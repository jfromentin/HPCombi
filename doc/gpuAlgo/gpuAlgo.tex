%Compilation
%pdflatex -synctex=1 -interaction=nonstopmode gpuAlgo.tex && bibtex gpuAlgo.aux && pdflatex -synctex=1 -interaction=nonstopmode gpuAlgo.tex && pdflatex -synctex=1 -interaction=nonstopmode gpuAlgo.tex

\newcommand{\path}{./}
\input{\path/entete}	
\input{\path/commandesImages}
\input{\path/glossaire}

\begin{document}
%\input{\path/tabulation}
\pagenumbering{gobble}
%\input{\path/pageDeGarde}
\pagestyle{empty}
\pagestyle{fancy}

\setlength{\headheight}{12pt}

\lhead{\leftmark}
\rhead{Daniel Vanzo}
\lfoot{\textsf{LRI}}
\cfoot{\thepage}
\rfoot{\MONTHENG\ \YEAR}

%\maketitle
\tableofcontents
\newpage


\chapter{HPCombi On GPU}
%\label{label}
\pagenumbering{arabic}
 
\section{Introduction}
Transformations on [1,n] are stored as an array, for example for n=4 :\\
The array $2|4|1|3$ represents the transformation that sends 1 on 2, 2 on 4, 3 on 1 and 4 on 3.
Let $G$ be a set of transformations called generators. We aim at finding properties about the set of transformations generated by the composition of those generators.
The composition of two transformation $g_2\circ g_1$ can be seen as the shuffling of $g_2$ according to $g_1$ :
\begin{eqnarray*}
g_1 &=& 2|4|1|3\\
g_2 &=& 1|3|4|2\\
g_2\circ g_1 &=& 3|2|1|4
\end{eqnarray*}
Let $T_k$ be the set of transformations to test and $F_k$ the set of already found transformations at the stage number $k$. Initialy $T_1 = F_1 = \{Id\}$, where $Id = 1|2|3|...|n.$\\
At stage number $k$, all element of $T_k$ are composed with all generators in $G$. The resulting transformations are then compared with transformations in $F_k$ and added, if absent, in $F_k$.\\ 
A word is defined as a suit of generators to compose with the identity transformation, Id.
The first words from which we obtain a particular transformation is stored in a hash table.
The keys for the hash table are set to be structures containing a hash value and a word. The hash value allows fast distinction of keys and the word allows to compute the transformation. Detail discussion about keys comparison is in \autoref{part:equality}.

All transformations composition occurring at a stage can be computed in parallel. After composing the transformations, all hash value can be computed in parallel as well. Depending on the hash table implementation, transformations can, or not, be inserted in parallel.\\
The first implementation of the program uses Google Sparsehash as the hash table which only allows sequential insertions. Further implementation could use a hash table on the \gls{gpu} as shown in \cite{wen2011gpu}.

%To explore all possible transformation generated by a set of generator,
%Those shuffeling operation are done efficiently with x86 vector instructions for n up to 256.
%GPUs could be used to do those operation for n > 256.

\section{Composition algorithm}
Let's assume one thread should compose all generators contained in a word to the identity transformation, Id. Two loops are necessary, one to iterate over the generators in the word, the second to iterate over the transformations elements.
\autoref{algo:composebad} shows the algorithm for which the outer loop iterates over the generators and the inner loop iterates over the elements.
\begin{itemize}
\item A temporary array resultTMP must be allocated to store intermediate results.
\item Multiple loop over the elements are needed to :
\begin{enumerate}
 \item Initialize the result array to identity,
 \item Compose with one generator,
 \item Copy temporary results into the result array.
 \end{enumerate}
\item Access to the generators array is only done once for each generator,
 \item Accesses to the generators component are contiguous,
 \item Parallelization of the outer loop require synchronization of all treads.
\end{itemize}
\autoref{algo:composegood} shows the algorithm for which the outer loop iterates over the elements and the inner loop iterates over the generators.
\begin{itemize}
 \item No temporary array is needed, memory consumption is halved compared to \autoref{algo:composebad},
 \item Only one loop over the elements is needed,
 \item Multiple access to the same generator are done, as many as the size of the transformation,
 \item Accesses to the generators component are not contiguous,
 \item The outer loop can easily be parallelized without need for explicit synchronization.
\end{itemize}
\gls{gpu} threads can be synchronized in a \gls{cbloc} whereas threads in different \glspl{cbloc} can't be synchronized. Indeed, there is no guarantee \glspl{cbloc} are executed in parallel, as a consequence, synchronization between \glspl{cbloc} could lead to dead blocks. Hence a parallel implementation of \autoref{algo:composebad} would require transformations elements to be spread over a maximum of 1024 threads, the maximum number of threads in a \gls{cbloc}.

The later limitation on parallelism, the doubling of memory consumption and the need for three loops over the elements in \autoref{algo:composebad} made us choose the \autoref{algo:composegood} for the starting point of the parallel implementation.
\autoref{algo:composepar} is a parallelized version for \gls{gpu} of \autoref{algo:composegood}. The outer loop is basically replaced by a "if" statement selecting threads that should compute the instructions. Each threads applies all compositions to one element. To adapt granularity, one can mix \autoref{algo:composegood} and \autoref{algo:composepar} to assign several elements to each threads on which to compose all generators in a word.
When several words are requested, more parallelism can be extracted, indeed, each word can be computed in parallel. Hence two levels of parallelism can be exploited, parallelism over several words and parallelism over elements of the transformations. One should find a good balance between both:
\begin{itemize}
\item When few words are to be computed, transformations elements should be spread over lots of threads to exploit parallelism,
\item When lots of word are to be computed, transformations elements should be assigned to few threads for greater granularity and thread number limitation. compliance.
\end{itemize}
Parallelism is dynamically tuned during the execution according to the number of word to be computed.



\begin{algorithm}
\caption{Outer loop on generators, inner loop on elements}
\label{algo:composebad}
\begin{algorithmic}
\FOR{$0 < elem < size$}
\STATE $result(elem) = elem$
\ENDFOR
\FOR{$0 < j < sizeWord$}
\STATE $gen = word(j)$
\FOR{$0 < elem < size$}
\STATE $index = gen(elem)$
\STATE $resultTMP(elem) = result(index)$
\ENDFOR
\STATE $index = newGen(index)$
\STATE $resultTMP(elem) = result(index)$
\FOR{$0 < elem < size$}
\STATE $result(elem) = resultTMP(elem)$
\ENDFOR
%\STATE Synchronise
\ENDFOR
\end{algorithmic}
\end{algorithm}



\begin{algorithm}
\caption{Outer loop on elements, inner loop on generators}
\label{algo:composegood}
\begin{algorithmic}
\FOR{$0 < elem < size$}
\STATE $index = elem$
\FOR{$0 < j < sizeWord$}
\STATE $gen = word(j)$
\STATE $index = gen(index)$
\ENDFOR
\STATE $index = newGen(index)$
\STATE $result(elem) = index$
\ENDFOR
\end{algorithmic}
\end{algorithm}


\begin{algorithm}
\caption{Outer loop on elements, inner loop on generators with multiple threads}
\label{algo:composepar}
\begin{algorithmic}
\IF{$0 < threadId < size$}
\STATE $index = threadId$
\FOR{$0 < j < sizeWord$}
\STATE $gen = word(j)$
\STATE $index = gen(index)$
\ENDFOR
\STATE $index = newGen(index)$
\STATE $result(threadId) = index$
\ENDIF
\end{algorithmic}
\end{algorithm}


\section{Hash algorithm}
Let $t$ be a transformation and $P_{t}$ be the polynomial $\displaystyle\sum_{i=1}^{size} t(i)X^i$. The hash function is defined as $hash(t) = P_{t}(prime)$, where $prime$ is a prime number.
The polynomial value is computed with the Ruffini-Horner method.
\begin{algorithm}
\caption{Hashing}
\label{algo:hash}
\begin{algorithmic}
\STATE $prime = PrimeNumber$
\STATE $result = prime \times trans(0)$
\FOR{$1 < i < size$}
\STATE $\switch result += trans(i)$
\STATE $\switch result *= prime$
\ENDFOR
\end{algorithmic}
\end{algorithm}
Parallelism is obtained by assigning one hash value computation per thread.
One could parallelize the computing of one hash value and think of tuning parallelism dynamically as done for the words computation. This is not trivial because the computation of a hash value involves overflows. As a consequence a direct parallelization of \autoref{algo:hash} would give different results depending of the number of threads used for a hash value computation. Dynamically adapting the number of thread computing a hash value during a execution would lead two false results. A more advanced algorithm is needed, assuring the exacts same overflows occurs regardless of the number of threads involved in the hash value computation. As the hash values computation is not a bottleneck in our example, this as not be tested, each thread compute a hash value regardless of the size of the transformations.


\section{Transformations equality}
\label{part:equality}
When inserting a new element in the hash table, tests for keys equality are preformed.
Remind that a key is a structure containing a hash value and a word.
To compare two keys, first the hash values are compared. If they are different, transformation are different.
If the hash value are identical the transformations have to be compared coefficient by coefficient. The words allow to compute both transformations and compare them coefficient by coefficient as shown in \autoref{algo:equal}.
In the \gls{gpu} version each thread computes a coefficient for both transformation according to \autoref{algo:composepar}. Then each thread compares the resulting coefficients and store the result in the $equal$ variable. The sum of each thread's $equal$ variable is then computed and compared to the size of the transformations.

The execution time of the equality test on \gls{gpu} is dominated by \gls{cpu}/\gls{gpu} data copy, kernel launching latency and \gls{cpu}/\gls{gpu} synchronization. This is demonstrated in \autoref{benchgpu}, which is a profiling the the execution of the Bihecke 5 and Renner A 7 tests cases. Details about test cases are in \autoref{part:results}.
Testing equality on \gls{cpu} avoids the overhead of copying data to the \gls{gpu}, kernel launching latency and \gls{cpu}/\gls{gpu} synchronization.
\autoref{equalcpugpu} compares the time to test for equality in different test cases on the \gls{cpu} on one hand and on the \gls{gpu} on the other hand. When transformation sizes are small (24, 120) it is faster on \gls{cpu}, when transformation sizes are big (13327, 130922) it is faster on \gls{gpu}. The size where \glspl{gpu} are faster than \glspl{cpu} seems to be around 1000.

All runs in this section are executed on \gls{e51650} as the \gls{cpu} and \gls{1080} as the \gls{gpu}.

\begin{table}
\centering
\begin{tabular}{ p{2cm} |>{\centering\arraybackslash}p{2.5cm} |> {\centering\arraybackslash}p{1.5cm} > {\centering\arraybackslash}p{3cm} > {\centering\arraybackslash}p{3cm} }
 Test case & Kernel computation (s) & Data Copy (s) & Kernel launching latency (s) & \glstext{cpu}/\glstext{gpu} synchronization (s) \\
\hline
Bihecke 5 & 1.03 & 2.80 & 0.96 & 1.29 \\
Renner A 7 & 36.21 & 10.51 & 3.86 & 81.79 \\
\end{tabular}
\caption{}
\label{benchgpu}
\end{table} 

\begin{table}
\centering
\begin{tabular}{ p{3cm} |>{\centering\arraybackslash}p{2cm} |> {\centering\arraybackslash}p{3cm} > {\centering\arraybackslash}p{3cm} }
 Test case & Size & Time on \glstext{cpu} (s) & Time on \glstext{gpu} (s) \\
\hline
Bihecke 4 & 24 & 0.0007 & 0.044 \\
Bihecke 5 & 120 & 0.187 & 3.37 \\
Bihecke 6 (partial) & 720 &  &  \\
Renner A 6 & 13327 & 7.85 & 1.11 \\
Renner A 7 & 130922 & 1320 & 45.6 \\
\end{tabular}
\caption{}
\label{equalcpugpu}
\end{table} 
 
\begin{algorithm}
\caption{Equality testing}
\label{algo:equal}
\begin{algorithmic}
\IF{$0 < threadId < size$}
\STATE $index = threadId$
\STATE equal = 0
\FOR{$0 < j < sizeWord$}
\STATE $gen1 = word(j)$
\STATE $gen2 = word(j)$
\STATE $index1 = gen1(index1)$
\STATE $index2 = gen2(index2)$
\ENDFOR
\IF{index1 = index2}
\STATE equal = 1
\ENDIF
\ENDIF
\STATE Sum(equal)
\end{algorithmic}
\end{algorithm}

\section{Duplicates elimination on GPU}
At each stage, new computed transformations are inserted in the hash table located on the \gls{cpu}. This require to test if the hash table location attributed to the transformation is empty, introducing a memory fetch. Those memory fetch are random as a consequence of the hash function efficiency. When the hash table becomes big enough, it doesn't fit entirely in the \gls{cpu} cache and lots of cache misses occurs.
To limit the number of cache misses we should limit the number of insertion attempts in the hash table. For that purpose a kernel is executed on the \gls{gpu} to eliminate duplicates within the set of transformations computed at a particular stage. This kernel is described is \autoref{algo:preinsert}. As a result the set of transformations that the \gls{cpu} attempt to insert in the hash table is smaller. The number of transformations send bask to the \gls{cpu} is about 3 times smaller, this is shown in \autoref{preinsert}. Details about test cases are in \autoref{part:results}.

In our implementation, hash value are computed before the elimination of duplicates, which allows to first compare hash value before comparing the transformations coefficient by coefficient. The down side of this ordering is that some hash value computation could be avoided. Indeed if the duplicates are eliminated before computing the hash value, 3 times less hash value would be computed. Benchmarks in \autoref{part:results} show that the hash values computation is cheap compared to the elimination of duplicates, hence computing the hash value first to accelerate duplicates elimination is the better choice.

As for the composition algorithm, a \gls{gpu} version of \autoref{algo:preinsert} is obtained by replacing by the outer loop with a "if" statement selecting threads that should compute the instructions.

The inner loop iterating over the elements of a transformation could be stopped the first time an non equality occurs. This appended to be much slower for the examples tested in \autoref{part:results}. Two hypothesis, to be confirmed, could explain why :
\begin{itemize}
\item The additional loop control instructions resulting from the \emph{break} instruction are not efficiently handled by the \gls{gpu}.
\item The \emph{break} instruction results in more warp divergence, which implies serialization of execution \cite{doccuda}.
\end{itemize}

\begin{table}
\centering
\begin{tabular}{ p{3cm} |>{\centering\arraybackslash}p{2cm} > {\centering\arraybackslash}p{3cm} }
Test case & Size & \% of eliminated transformations \\
\hline
Bihecke 4 & 24 & 57\% \\
Bihecke 5 & 120 & 64\% \\
Bihecke 6 (partial) & 720 & \% \\
Renner A 6 & 13327 & 64\% \\
Renner A 7 & 130922 & 66\% \\
\end{tabular}
\caption{}
\label{preinsert}
\end{table} 

\begin{algorithm}
\caption{Eliminating duplicates}
\label{algo:preinsert}
\begin{algorithmic}
\FOR{$0 < trans < nb\_trans$}
\STATE $equal = 0$
\FOR{$0 < other < trans$}
\IF{hash(trans) = hash(other)}
\FOR{$0 < i < size$}
\IF{trans(i) = other(i)}
\STATE equal += 1
\ENDIF
\ENDFOR
\IF{equal = size}
\STATE Suppress $trans$
\ENDIF
\ENDIF
\ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm}


\section{Results}
\label{part:results}

For the following benchmarks equality testing is always done on the \gls{gpu}.
Three sets of generators are tested :
\begin{itemize}
\item Renner A7: 7 generators of size 130922,
\item Bihecke 5: 8 generators of size 120,
\item Bihecke 6: 10 generators of size 720.
\end{itemize}
%The size of the transformations has a notable influence on performances. The high thread count of \glspl{gpu} allow to efficiently compute big transformations.
All runs in this section are executed on \gls{e51650} as the \gls{cpu} and \gls{1080} as the \gls{gpu}.

\begin{table}
\centering
\begin{tabular}{ p{3cm} |>{\centering\arraybackslash}p{1.3cm} |> {\centering\arraybackslash}p{2cm} > {\centering\arraybackslash}p{1.3cm} > {\centering\arraybackslash}p{1.3cm} > {\centering\arraybackslash}p{1.3cm} > {\centering\arraybackslash}p{1.3cm} }
 & Total time (s) & Composition (s) & Hash (s) & Equality (s) & Sort (s) & Insert (s) \\
\hline
\glstext{cpu} & 66.9 & 0.02 & 0.03 & 0.55 & 0.00 & 66.2 \\

\glstext{gpu} & 72.6 & 0.002 & 0.002 & 9.3 & 0.00 & 63.3 \\

\glstext{gpu} (sort) & 27.2 & 0.002 & 0.002 & 3.37 & 0.06 & 23.8 \\
\hline
Speed up \newline \glstext{cpu}/\glstext{gpu} (sort) & 2.5 & 10 & 15 & 1/6 & 0 & 2.8 \\
\end{tabular}
\caption{Bihecke 5}
\label{resultsb}
\end{table}

\begin{table}
\centering
\begin{tabular}{ p{3cm} |>{\centering\arraybackslash}p{1.3cm} |> {\centering\arraybackslash}p{2cm} > {\centering\arraybackslash}p{1.3cm} > {\centering\arraybackslash}p{1.3cm} > {\centering\arraybackslash}p{1.3cm} > {\centering\arraybackslash}p{1.3cm} }
 & Total time (s) & Composition (s) & Hash (s) & Equality (s) & Sort (s) & Insert (s) \\
\hline
\glstext{cpu} & 8440 & 260 & 238 & 5870 & 0.00 & 1990 \\

\glstext{gpu} & 1390 & 10.2 & 12.7 & 155 & 0.00 & 1170 \\

\glstext{gpu} (sort) & 524 & 10.2 & 12.7 & 45.9 & 22.1 & 391 \\
\hline
Speed up \newline \glstext{cpu}/\glstext{gpu} (sort) & 16 & 25 & 19 & 128 & 0 & 5 \\
\end{tabular}
\caption{Renner A7}
\label{resultsr}
\end{table}

\section{Sources}
\emph{git clone -b rennergpu https://github.com/hivert/HPCombi.git}


\bibliographystyle{plain}
\bibliography{biblio}

\end{document}

