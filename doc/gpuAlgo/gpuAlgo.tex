%Compilation
%pdflatex -synctex=1 -interaction=nonstopmode gpuAlgo.tex && bibtex gpuAlgo.aux && pdflatex -synctex=1 -interaction=nonstopmode gpuAlgo.tex && pdflatex -synctex=1 -interaction=nonstopmode gpuAlgo.tex

\newcommand{\path}{./}
\input{\path/entete}	
\input{\path/commandesImages}
\input{\path/glossaire}

\begin{document}
%\input{\path/tabulation}
\pagenumbering{gobble}
%\input{\path/pageDeGarde}
\pagestyle{empty}
\pagestyle{fancy}

\setlength{\headheight}{12pt}

\lhead{\leftmark}
\rhead{Daniel Vanzo}
\lfoot{\textsf{LRI}}
\cfoot{\thepage}
\rfoot{\MONTHENG\ \YEAR}

%\maketitle
\tableofcontents
\newpage


\chapter{HPCombi On GPU}
%\label{label}
\pagenumbering{arabic}
 
\section{Introduction}
Transformations of [1,n] are stored as an array, for example for n=4 :\\
The array $2|4|1|3$ represents the transformation that sends 1 on 2, 2 on 4, 3 on 1 and 4 on 3.
Let $G$ be a set of transformations called generators. We aim at finding properties about the set of transformations generated by the composition of those generators.
The composition of two transformation $g_2\circ g_1$ can be seen as the shuffling of $g_2$ according to $g_1$ :
\begin{eqnarray*}
g_1 &=& 2|4|1|3\\
g_2 &=& 1|3|4|2\\
g_2\circ g_1 &=& 3|2|1|4
\end{eqnarray*}
Let $T_k$ be the set of transformations to test and $F_k$ the set of already found transformations at the stage number $k$. Initialy $T_1 = F_1 = \{Id\}$, where $Id = 1|2|3|...|n.$\\
At stage number $k$, all element of $T_k$ are composed with all generators in $G$. The resulting transformations are then compared with transformations in $F_k$ and added, if absent, in $F_k$.\\ 
A word is defined as a suit of generators to compose with the identity transformation, Id.
The first words from which we obtain a particular transformation is stored in a hash table.
The keys for the hash table are set to be structures containing a hash value and a word. The hash value allows fast distinction of keys and the word allows to compute the transformation. Detail discussion about keys comparison is in \autoref{part:equality}.

All transformations composition occurring at a stage can be computed in parallel. After composing the transformations, all hash value can be computed in parallel as well. Depending on the hash table implementation, transformations can, or not, be inserted in parallel.\\
The first implementation of the program uses Google Sparsehash as the hash table which only allows sequential insertions. Further implementation could use a \gls{gpu} hash table as shown in \cite{wen2011gpu}.

%To explore all possible transformation generated by a set of generator,
%Those shuffeling operation are done efficiently with x86 vector instructions for n up to 256.
%GPUs could be used to do those operation for n > 256.

\section{Composition algorithm}
Let's assume one thread should compose all generators contained in a word to the identity transformation, Id. Two loops are necessary, one to iterate over the generators in the word, the second to iterate over the transformations elements.
\autoref{algo:composebad} shows the algorithm for which the outer loop iterates over the generators and the inner loop iterates over the elements.
\begin{itemize}
\item A temporary array resultTMP must be allocated to store intermediate results.
\item Multiple loop over the elements are needed to :
\begin{enumerate}
 \item Initialize the result array to identity,
 \item Compose with one generator,
 \item Copy temporary results into the result array.
 \end{enumerate}
\item Access to the generators array is only done once for each generator,
 \item Accesses to the generators component are contiguous,
 \item Parallelization of the outer loop require synchronization of all treads.
\end{itemize}
\autoref{algo:composegood} shows the algorithm for which the outer loop iterates over the elements and the inner loop iterates over the generators.
\begin{itemize}
 \item No temporary array is needed, memory consumption is halved compared to \autoref{algo:composebad},
 \item Only one loop over the elements is needed,
 \item Multiple access to the same generator are done, as many as the size of the transformation,
 \item Accesses to the generators component are not contiguous,
 \item The outer loop can easily be parallelized without need for explicit synchronization.
\end{itemize}
\gls{gpu} threads can be synchronized in a \gls{cbloc} whereas threads in different \glspl{cbloc} can't be synchronized. Indeed, there is no guarantee \glspl{cbloc} are executed in parallel, as a consequence, synchronization between \glspl{cbloc} could lead to dead blocks. Hence a parallel implementation of \autoref{algo:composebad} would require transformations elements to be spread over a maximum of 1024 threads, the maximum number of threads in a \gls{cbloc}.

The later limitation on parallelism, the doubling of memory consumption and the need for three loops over the elements in \autoref{algo:composebad} made us choose the \autoref{algo:composegood} for the starting point of the parallel implementation.
\autoref{algo:composepar} is a parallelized version for \gls{gpu} of \autoref{algo:composegood}. The outer loop is basically replaced by a "if" statement selecting threads that should compute the instructions. Each threads applies all compositions to one element. To adapt granularity, one can mix \autoref{algo:composegood} and \autoref{algo:composepar} to assign several elements to each threads on which to compose all generators in a word.
When several words are requested, more parallelism can be extracted, indeed, each word can be computed in parallel. Hence two levels of parallelism can be exploited, parallelism over several words and parallelism over elements of the transformations. One should find a good balance between both:
\begin{itemize}
\item When few words are to be computed, transformations elements should be spread over lots of threads to exploit parallelism,
\item When lots of word are to be computed, transformations elements should be assigned to few threads for greater granularity and thread number limitation. compliance.
\end{itemize}
Parallelism is dynamically tuned during the execution according to the number of word to be computed.



\begin{algorithm}
\caption{Outer loop on generators, inner loop on elements}
\label{algo:composebad}
\begin{algorithmic}
\FOR{$0 < elem < size$}
\STATE $result(elem) = elem$
\ENDFOR
\FOR{$0 < j < sizeWord$}
\STATE $gen = word(j)$
\FOR{$0 < elem < size$}
\STATE $index = gen(elem)$
\STATE $resultTMP(elem) = result(index)$
\ENDFOR
\STATE $index = newGen(index)$
\STATE $resultTMP(elem) = result(index)$
\FOR{$0 < elem < size$}
\STATE $result(elem) = resultTMP(elem)$
\ENDFOR
%\STATE Synchronise
\ENDFOR
\end{algorithmic}
\end{algorithm}



\begin{algorithm}
\caption{Outer loop on elements, inner loop on generators}
\label{algo:composegood}
\begin{algorithmic}
\FOR{$0 < elem < size$}
\STATE $index = elem$
\FOR{$0 < j < sizeWord$}
\STATE $gen = word(j)$
\STATE $index = gen(index)$
\ENDFOR
\STATE $index = newGen(index)$
\STATE $result(elem) = index$
\ENDFOR
\end{algorithmic}
\end{algorithm}


\begin{algorithm}
\caption{Outer loop on elements, inner loop on generators with multiple threads}
\label{algo:composepar}
\begin{algorithmic}
\IF{$0 < threadId < size$}
\STATE $index = threadId$
\FOR{$0 < j < sizeWord$}
\STATE $gen = word(j)$
\STATE $index = gen(index)$
\ENDFOR
\STATE $index = newGen(index)$
\STATE $result(threadId) = index$
\ENDIF
\end{algorithmic}
\end{algorithm}


\section{Hash algorithm}
Let $t$ be a transformation and $P_{t}$ be the polynomial $\displaystyle\sum_{i=1}^{size} t(i)X^i$. The hash function is defined as $hash(t) = P_{t}(prime)$, where $prime$ is a prime number.
The polynomial value is computed with the Ruffini-Horner method.
\begin{algorithm}
\caption{Hashing}
\label{algo:hash}
\begin{algorithmic}
\STATE $prime = PrimeNumber$
\STATE $result = prime \times trans(0)$
\FOR{$1 < i < size$}
\STATE $\switch result += trans(i)$
\STATE $\switch result *= prime$
\ENDFOR
\end{algorithmic}
\end{algorithm}
Parallelism is obtained by assigning one hash value computation per thread.
One could parallelize the computing of one hash value and think of tuning parallelism dynamically as done for the words computation. This is not trivial because the computation of a hash value involves overflows. As a consequence a direct parallelization of \autoref{algo:hash} would give different results depending of the number of threads used for a hash value computation. Dynamically adapting the number of thread computing a hash value during a execution would lead two false results. A more advanced algorithm is needed, assuring the exacts same overflows occurs regardless of the number of threads involved in the hash value computation. As the hash values computation is not a bottleneck in our example, this as not be tested, each thread compute a hash value regardless of the size of the transformations.


\section{Transformations equality}
\label{part:equality}
When inserting a new element in the hash table, tests for keys equality are preformed.
Remind that a key is a structure containing a hash value and a word.
To compare two keys, first the hash values are compared. If they are different, transformation are different.
If the hash value are identical the transformations have to be compared coefficient by coefficient. The words allow to compute both transformations and compare them coefficient by coefficient as shown in \autoref{algo:equal}.
Each thread computes a coefficient for both transformation according to \autoref{algo:composepar}. Then each thread compares the resulting coefficients and store the result in the $equal$ variable. The sum of each thread's $equal$ variable is then computed and compared to the size of the transformations.
 
\begin{algorithm}
\caption{Equality testing}
\label{algo:equal}
\begin{algorithmic}
\IF{$0 < threadId < size$}
\STATE $index = threadId$
\STATE equal = 0
\FOR{$0 < j < sizeWord$}
\STATE $gen1 = word(j)$
\STATE $gen2 = word(j)$
\STATE $index1 = gen1(index1)$
\STATE $index2 = gen2(index2)$
\ENDFOR
\IF{index1 = index2}
\STATE equal = 1
\ENDIF
\ENDIF
\STATE Sum(equal)
\end{algorithmic}
\end{algorithm}


\section{Results}

\begin{table}
\centering
\begin{tabular}{p{1.5cm}p{3.0cm}|>{\centering\arraybackslash}p{1.5cm}|>{\centering\arraybackslash}p{1.5cm}|>{\centering\arraybackslash}p{1.5cm}}
 & On \glstext{gpu} & Total time & Time on \glstext{gpu} & Time on \glstext{cpu} \\
\hline
Bihecke5 &  &  &  &  \\
& Composition hash &  &  &  \\
& Equality&  &  &  \\
& Sort&  &  &  \\
\hline
RenA7 &  &  &  &  \\
& Composition hash &  &  &  \\
& Equality&  &  &  \\
& Sort&  &  &  \\

\end{tabular}
\caption{Legende }
\label{results}
\end{table}




\section{Sources}
\emph{git clone -b rennergpu https://github.com/hivert/HPCombi.git}


\bibliographystyle{plain}
\bibliography{biblio}

\end{document}

